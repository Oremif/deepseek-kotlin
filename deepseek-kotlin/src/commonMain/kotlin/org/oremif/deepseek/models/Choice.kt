package org.oremif.deepseek.models

import kotlinx.serialization.Serializable

/**
 * @property finishReason The reason the model stopped generating tokens.
 * This will be `stop` if the model hit a natural stop point or a provided stop sequence,
 * `length` if the maximum number of tokens specified in the request was reached,
 * `content_filter` if content was omitted due to a flag from our content filters,
 * `tool_calls` if the model called a tool,
 * or `insufficient_system_resource` if the request is interrupted due to insufficient resource of the inference system.
 * @property index The index of the choice in the list of choices.
 * @property message A chat completion message generated by the model.
 * @property logprobs Log probability information for the choice.
 */
@Serializable
public class Choice(
    public val finishReason: FinishReason,
    public val index: Long,
    public val message: ChatCompletionMessage,
    public val logprobs: LogProbs? = null,
) {
    override fun equals(other: Any?): Boolean {
        if (this === other) return true
        if (other !is Choice) return false

        return index == other.index &&
                finishReason == other.finishReason &&
                message == other.message &&
                logprobs == other.logprobs
    }

    override fun hashCode(): Int {
        var result = index.hashCode()
        result = 31 * result + finishReason.hashCode()
        result = 31 * result + message.hashCode()
        result = 31 * result + (logprobs?.hashCode() ?: 0)
        return result
    }

    override fun toString(): String =
        "ChatCompletionChoice(finishReason=$finishReason, index=$index, message=$message, logprobs=$logprobs)"
}